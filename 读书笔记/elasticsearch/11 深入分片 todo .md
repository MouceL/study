## 第 11 章  深入分片

https://www.cnblogs.com/wenBlog/p/8489197.html

### 11.1 使文本可以被搜索

倒排索引 --  倒排 term ---   
怎么找term呢 hash+list 或者   b 树 结构，找到term,trem 对应着该次出现在那些文档中。





不可变性，写入磁盘的倒排索引是不可改的，也就不担心并发写。 索引被读入内存后就常驻内存，提高了查询性能





动态更新索引

如何在不丢失不变形的好处下，让倒排索引可以修改呢？全部重写？方法是使用不止一个索引，利用新的索引反应新的更改。lucene 引入了  per-segment 的概念。 一个 segment是一个完整的倒排索引的子集。那么在lucene 中索引就是 segment 的集合。 

​	由多个 segment 和 内存buffer 组成， 当要加入新的文档时候，写入buffer中，每隔一段时间就会写入一个新的 segment。写入segment后可以被搜索。

​	当删除的时候，虽然segments是不变的，但是在每个提交的segment中有个 del 文件记录哪些文档被删除了，只是一个标记而已。被“删除”的文档可以被索引到，但是他将会在最终结果返回时被除掉。

​	更新同理，旧版本文档被标记为删除，新版在新的segment中建立。



实时索引

​	上述的per-segment 搜索机制下，新的文档会在分钟级内被索引，但是还是不够快。瓶颈在磁盘，你将buffer 内容写入磁盘fsync需要时间，而只有被写入磁盘的文档才是可搜索的。这就导致性能低。改进的方法是，在es和物理磁盘之前是内核的文件系统缓存，那么可以将buffer首先写到内核的文件系统缓存，这个过程是轻量的，然后再flush 到磁盘。一旦一个segment 文件再内核缓存中，它可以被打开被读取。



持久

 当一个文档被索引时，它会被添加到buffer ，并且写入 translog 日志中，buffer一直写入内核文件，当translog变得非常大时，索引被flush 新的translog 将会被建立，一个完全的提交进行完毕。

translog 日志提供了一个所有未被flush 到磁盘的操作的持久化记录。



segment 合并

​	通过每隔一秒的自动刷新机制会创建一个新的segment，那么就需要merge. 这个过程也是被哪些被 “删除” 的文档真正被清除出文档系统的过程，因为被标记为删除的文档不会被拷贝到大的 segment中







































更新持久化

​	不使用fsync 将数据flush 到磁盘，不能保障断电不丢。





