日志存储

​	Kafka 按照topic 将消息进行分类，每个topic 是一个逻辑上的分类，在存储层面是由多个partition构成。每个partition 对应着broker上的一个磁盘目录，每个被发往该分区的消息都会以append的方式追加到在这个磁盘目录中。

​	为了避免分区的 log的日志太大，所以又将log日志分成了多个segment，只有最后一个segment是活动segment，也就是可以追加写入，其余的segment都是只读的。每个segment 主要有三个部分组成

~~~
 	1. log 文件，存储实际的数据
 	2. offset index 文件，存储offset 对应的消息在 log 文件中的具体位置
 	3. Timestamp index 文件，存储时间戳对应的相对 offset， 相对于offset index 的fisrt index.	
~~~

##### offset index	

寻找一个offset 对应的数据，首先根据offset 找到对应的segment，然后用offset-firstoffset计算出相对offset, 拿着这个相对offset去offset index中利用二分查找找对应的数据。offset index 是一个稀疏索引，它不会记录所有的相对offset, 所以需要找到不大于相对offset最大的offset对应的记录，然后那这个这个记录对应的位置信息去log文件中顺序查找。

##### Timestamp index

如果是按照时间索引去查找targettimestamp，首先会跟每个日志分段中的最大时间戳对比，找到不小于targettimestamp的lasttimestamp 所在的分段。找到分段后，利用二分查找，找到不大于targettimestamp的最大索引项，然后取出targetoffset,然后查找方式跟上面查找一样。

##### 格式

log中存储的日志的格式有几个版本，但是都要有以下信息，offset, value, timestamp, version。现在就说下v2版本，多个record 会组成一个record batch，大概的这个batch中 header(first offset , first timestamp, record count , max timestamp ) + records(多个record) 。

##### 日志删除

磁盘容量不是无限的，所以需要定期的清理一批数据以释放磁盘存储。kafka 提供了三种方式清理磁盘

~~~
1. 按时间戳清理，会有个选项设置日志保留天数，然后后台会不停的查找过期的分段，查找过程是查询每个时间索引文件的最大时间戳，如果不在保留期间，那么会被标志成delete. 后台会有任务删除这些被标志成delete的文件。
2. 按文件大小清理，每个log 都设定了一个阈值，多个segment的和。如果大于阈值，那么就会从第一个日志分段开始进行查找可删除的分段。
3. 按照offset清理，通过deleteRequest 传递 logStartOffset的方法进行操作，遍历每一个分段，找到第一个大于等于logStartOffset的分段，然后删除之前的所有分段。
~~~

##### 日志 compact

这会被称作日志压缩，其实并不是，compression才是压缩。 这里的 compact 指的是如果key相同，那么log中将只保留最新的key-value. 它会将多个segment进行分组，每个组中的segment 会进行一次合并，合并的过程是，首先遍历这个组中的segment的所有元素，构建一个map ,key为消息的key的MD5值，value是消息的offset值。在构建完毕后，再遍历组内所有offset，只保留大的offset.

##### 磁盘存储

当听到kafka是磁盘存储的时候，不要吃惊。我们平常认为的写入慢是我们进行了随机的写，线性写入磁盘的速度要远超我们的想象。kafka 只允许以追加的方式写入磁盘，这就是快速的一个基础。

##### 页缓存

##### 零拷贝

这么理解，你需要将一个资源展示给用户

~~~
1. 读到内核的read buffer中
2. 将数据复制到用户模式下。
3. 调用write方法，将用户模式下的数据复制到内核模式的socket中
4. 将内核模式下 socket 的数据复制的网卡中。
~~~

这样就在第2第3 步的时候从内核到用户，从用户再到内核。这样白白浪费了两次拷贝。零拷贝技术就是讲数据直接读到内核 readBuffer 中，然后直接发送的网卡？？ 只需要两次拷贝。

