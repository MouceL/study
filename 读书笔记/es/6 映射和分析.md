## 第六章 映射和分析

### 6.1  数据类型差异

​	出现以下这种情况，在数据中包含12个tweets，但只有一个包含日期 2014-09-15，如果用下面方式进行查询会出现意想不到的结果

```
GET /_search?q=2014              # 12 个结果
GET /_search?q=2014-09-15        # 还是 12 个结果 !
GET /_search?q=date:2014-09-15   # 1  一个结果
GET /_search?q=date:2014         # 0  个结果 !
```

​	针对全文查询返回了所有的tweets，而针对date字段进行查询却什么都不返回。为什么查询会因查询字段不同而不同（_all 默认查询所有字段）。_all字段连接所有字段的值构成一个用空格（space）分隔的大string。 可以被analyzed 和 index ,_all 字段仅仅是一个经过分析的 string 字段。它使用默认的分析器来分析它的值，而不管这值本来所在的字段指定的分析器，以上现象是由于索引方式不同而导致的，

```
GET /gb/_mapping/tweet
{
   "gb": {
      "mappings": {
         "tweet": {
            "properties": {
               "date": {
                  "type": "date",
                  "format": "dateOptionalTime"
               },
               "name": {
                  "type": "string"
               },
               "tweet": {
                  "type": "string"
               },
               "user_id": {
                  "type": "long"
               }
            }
         }
      }
   }
}
```

​	可以看到，es 对数据类型进行了猜测，动态生成了字段类型,date字段被识别为 date 类型，而_all是默认字段所以没有展示，我们知道它是string 类型。date类型和string类型的字段索引方式是不同的，因此导致了查询结果的不同。不同的数据类型有不同的索引方式，它么在es中是区别对待的，更大的不同是 确切值 和 全文文本。

### 6.2 确切值与全文文本

​	es中的数据大致分为 确切值和 全文文本

​	确切值是一个确定的值，Foo 与 foo 是不同的， 2020 与2020-01-01也是不同的， 所以确切值是容易查询的，要么匹配要么不匹配，类似于sql

```
WHERE name    = "John Smith"
  AND user_id = 2
  AND date    > "2014-09-15"
```

​	但是对于全文数据来说，却有些微妙，我们不能确定这篇文档是否匹配查询，但是我们可以询问这篇文档和查询的匹配程度,也就是相关性有多高。

​	我们不能确切的匹配整个全文文档，我们想在全文查询中包括查询文本的部分，我们还希望搜索引擎理解我们的意图，一个针对uk的查询可以设计 united kingdom 文档，针对jumps 的查询同时能匹配 jumped jumps jumping 甚至leap。为了方便在全文文本字段进行这些查询，es 首先对文本分析，然后建立一个倒排索引。

### 6.3 倒排索引

​	倒排索引建立过程，如下有两个文档

```
The quick brown fox jumped over the lazy dog
Quick brown foxes leap over lazy dogs in summer
```

为了创建倒排索引，首先分割每个文档的字段为单独的单词，把结果放在列表中并排序，结果看起来如下

| Term   | Doc_1 | Doc_2 |
| ------ | ----- | ----- |
| Quick  |       | X     |
| The    | X     |       |
| brown  | X     | X     |
| dog    | X     |       |
| dogs   |       | X     |
| fox    | X     |       |
| foxes  |       | X     |
| in     |       | X     |
| jumped | X     |       |
| lazy   | X     | X     |
| leap   |       | X     |
| over   | X     | X     |
| quick  | X     |       |
| summer |       | X     |
| the    | X     |       |

​	现在如果想搜索 quick brown ，我们只需要找到每个词在哪个文档中出现即可

| Term  | Doc_1   | Doc_2 |
| ----- | ------- | ----- |
| brown | X       | X     |
| quick | X       |       |
| ----- | ------- | ----- |
| Total | 2       | 1     |

​	两个文档都匹配，但是第一个文档比第二个文档有更多的匹配项，如果加入简单的相似性算法，就可以得到相关性评分。但是Quick 和 quick 被认为是不同的单词，单用户可能认为它么是一致的。fox 和 foxes 很相似，就像dog 和 dogs 它们是同根词。jumped 和 leap 不是同根词，但是它么的意思相近

​	上面的索引中 “+Quick +fox”不会匹配到任何文档，前缀+表示必须匹配到。这样上面的查询就是Quick 和 fox必须在同一个文档中才能匹配。也就是同义词没法匹配。解决方法是，将词统一为标准格式，这样就可以找到上文中不是确切匹配，但是足以相似而可以相关联的文档，例如，Quick 可以转化成小写 quick ,foxes 可以被转化成根形式 fox ,jump 和 leap 同义,就可以只索引单个词jump

| Term   | Doc_1 | Doc_2 |
| ------ | ----- | ----- |
| brown  | X     | X     |
| dog    | X     | X     |
| fox    | X     | X     |
| in     |       | X     |
| jump   | X     | X     |
| lazy   | X     | X     |
| over   | X     | X     |
| quick  | X     | X     |
| summer |       | X     |
| the    | X     | X     |

​	我们的搜索`"+Quick +fox"`*依旧*失败，因为`"Quick"`的确切值已经不在索引里，不过，如果我们使用相同的标准化规则处理查询字符串的`content`字段，查询将变成`"+quick +fox"`，这样就可以匹配到两个文档。

### 6.4 分析

​	分析的过程如下，首先标记化一个文本块为一个个词，然后标准化这些词，提高它们的可搜索性。这个过程由分析器完成。分析器包括三个功能。



字符过滤器

字符串首先经过字符过滤器，它们的工作就是在标记化前处理字符串，它能够去除html 标记 或者转换&为 and



分词器

分词器用来标记单个词，既可以根据空格 也可以根据逗号进行分词



标记过滤

最后每个词都通过标记过滤，它可以修改词，进行标准化，去掉 the a and 等词，或者增加词如同义词 jump leap



es 通过许多开箱即用的字符过滤器 分词器 和 标记过滤器，它们可以自行组合应对不同的需求。



es 自带的分析器差异

```
"Set the shape to semi-transparent by calling set_trans(5)"
```

标准分析器

默认的分析器，对于文本分析，他对于任何语言都是最佳选择，根据[Unicode Consortium](http://www.unicode.org/reports/tr29/)的定义的**单词边界(word boundaries)**来切分文本，然后去掉大部分标点符号。最后，把所有词转为小写。产生的结果为：

```
set, the, shape, to, semi, transparent, by, calling, set_trans, 5
```



简单分析器

将非单个字母的文本切分，然后把每个词转换为小写

```
set, the, shape, to, semi, transparent, by, calling, set, trans
```

空格分析器

根据空格切分文本，不转换小写

```
Set, the, shape, to, semi-transparent, by, calling, set_trans(5)
```

语言分析器

特定语言分析器适用很多语言，它能考虑到很多语言特性，如english 分析器自带一套英语停用词库，想and the 这些与语义无关的都会被剔除

```
set, shape, semi, transpar, call, set_tran, 5
```

​	当我们索引一个文档的时候,全文字段会被分析为单独的词来创建倒排索引, 当我们全文搜索时，要让查询字符串经过同样的分析流程处理。

​	当查询full text 字段，查询将使用相同的分析器来分析查询的字符串，以产生正确的词列表

​	当查询一个 exact value 确切值 ,查询不分析查询字符串，但可以自己指定。

​	这里就可以知道本章开头，产生的结果，date 字段包含确切值，“2014-09-15”，_all 字段是一个全文字段，所以分析过程，将日期转换成三个词 2014 09 15 ，当我们在 _all 字段查询2014， 他匹配到了12条推文，这些词都包含 2014； 当查询2014-09-15，  首先分析查询字符串，产生匹配任一词 2014 09 15 的查询语句，它依旧匹配12个推文，当我们在 date字段查询 2014-09-15 ，它查询一个确切的值，然后只能查找到唯一一个推文，当我们在 date 字段中 查询 确切词 2014 ,没有匹配。



测试分析器



​	为了更好的理解es 是如何分词以及存储到索引 的，可以使用es 的 analyze api 查看

```
GET /_analyze?analyzer=standard&text=Text to analyze

=》》

{
   "tokens": [
      {
         "token":        "text",
         "start_offset": 0,
         "end_offset":   4,
         "type":         "<ALPHANUM>",
         "position":     1
      },
      {
         "token":        "to",
         "start_offset": 5,
         "end_offset":   7,
         "type":         "<ALPHANUM>",
         "position":     2
      },
      {
         "token":        "analyze",
         "start_offset": 8,
         "end_offset":   15,
         "type":         "<ALPHANUM>",
         "position":     3
      }
   ]
}
```

token 是实际被存储在索引中的词，position 指明词在原文本中是第几个出现的，start_offset  end_offset 表示词在原文本中占据的位置



指定分析器

当es 在你的文档中探测一个新的字符串字段，它将自动设置它为全文string字段 并用  standard 分析器分析。

在现实生产中，常常通过映射 设置这些字段。



### 6.6 映射 

​	es 需要知道每个索引的字段的类型，而不是去猜测它是什么类型，这些可以通过mapping设置

​	string  byte short integer long float double boolean date

​	如果es 不设置mapping ,es 通过 json 的基本类型来猜测类型。

| JSON type                          | Field type  |
| ---------------------------------- | ----------- |
| Boolean: `true` or `false`         | `"boolean"` |
| Whole number: `123`                | `"long"`    |
| Floating point: `123.45`           | `"double"`  |
| String, valid date: `"2014-09-15"` | `"date"`    |
| String: `"foo bar"`                | `"string`   |

查看映射

```
GET /gb/_mapping/tweet

==>>>

{
   "gb": {
      "mappings": {
         "tweet": {
            "properties": {
               "date": {
                  "type": "date",
                  "format": "strict_date_optional_time||epoch_millis"
               },
               "name": {
                  "type": "string"
               },
               "tweet": {
                  "type": "string"
               },
               "user_id": {
                  "type": "long"
               }
            }
         }
      }
   }
}
```

### 6.6 复合类型

​	除了之前体到的  string int 等简单类对象，json还有 null 数组 对象 ， es 同样支持这些



多值字段

我们想让 tag 字段包含多个字段，我们可以索引一个标签数组来代替单一字符串

```
{ "tag": [ "search", "nosql" ]}
```



空字段

lucence 没法存放null 值，所以一个 null 字段被认为是空子段，以下四个字段将被识别成空字段而不被索引

```
"empty_string":             "",
"null_value":               null,
"empty_array":              [],
"array_with_null_value":    [ null ]
```



多层对象

```
 "query_time": {
            "type": "nested",
            "properties": {
              "pct": {
                "type": "keyword"
              },
              "pct_95": {
                "type": "keyword"
              },
              "avg": {
                "type": "keyword"
              },
              "min": {
                "type": "keyword"
              },
              "median": {
                "type": "keyword"
              },
              "max": {
                "type": "keyword"
              },
              "sum": {
                "type": "keyword"
              },
              "stddev": {
                "type": "keyword"
              }
            }
          }
  
  
   {
    "Query_time":{
        "avg":"5023.000000",
        "max":"5023.000000",
        "median":"5023.000000",
        "min":"5023.000000",
        "pct":"1.000000",
        "pct_95":"5023.000000",
        "stddev":"0.000000",
        "sum":"5023.000000"
    }
}       

```

